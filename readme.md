# –°–∏—Å—Ç–µ–º–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –±–∞–∑—ñ Faster R-CNN

##  –û–ø–∏—Å –ø—Ä–æ—î–∫—Ç—É

–ü–æ–≤–Ω–æ—Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤, —è–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –¥–≤–æ—Å—Ç—É–ø–µ–Ω–µ–≤–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä **Faster R-CNN** –∑ backbone ResNet50-FPN. –°–∏—Å—Ç–µ–º–∞ –∑–∞–±–µ–∑–ø–µ—á—É—î:

-  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫—É –∑–æ–±—Ä–∞–∂–µ–Ω—å
-  –î–µ—Ç–µ–∫—Ü—ñ—é –æ–±'—î–∫—Ç—ñ–≤ –∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—î—é
-  –û–±—á–∏—Å–ª–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ —è–∫–æ—Å—Ç—ñ (IoU, mAP, Precision, Recall, F1-score)
-  –ù–∞–≤—á–∞–Ω–Ω—è —Ç–∞ –¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
-  –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω—É –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é –∑–≤—ñ—Ç—ñ–≤
-  –ë–∞–≥–∞—Ç–æ—Ñ–∞–π–ª–æ–≤—É –º–æ–¥—É–ª—å–Ω—É –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É

## –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ—î–∫—Ç—É


faster_rcnn_system/
‚îú‚îÄ‚îÄ config.py              # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏
‚îú‚îÄ‚îÄ utils.py               # –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
‚îú‚îÄ‚îÄ model.py               # Faster R-CNN –º–æ–¥–µ–ª—å
‚îú‚îÄ‚îÄ visualizer.py          # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
‚îú‚îÄ‚îÄ metrics.py             # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫
‚îú‚îÄ‚îÄ dataset.py             # –†–æ–±–æ—Ç–∞ –∑ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
‚îú‚îÄ‚îÄ trainer.py             # –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
‚îú‚îÄ‚îÄ report_generator.py    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤
‚îú‚îÄ‚îÄ main.py               # –ì–æ–ª–æ–≤–Ω–∏–π –º–æ–¥—É–ª—å
‚îî‚îÄ‚îÄ README.md             # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è
‚îî‚îÄ‚îÄconverter.py            #–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –ê–Ω–æ—Ç–∞—Ü—ñ–π


##  –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### 1. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω–∏–π —Ä–µ–∂–∏–º

–ó–∞–ø—É—Å–∫ –ø–æ–≤–Ω–æ—ó –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π —Å–∏—Å—Ç–µ–º–∏:


python main.py --mode demo


–¶–µ–π —Ä–µ–∂–∏–º:
- –°—Ç–≤–æ—Ä—é—î —Ç–µ—Å—Ç–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç
- –í–∏–∫–æ–Ω—É—î –¥–µ—Ç–µ–∫—Ü—ñ—é –æ–±'—î–∫—Ç—ñ–≤
- –ë—É–¥—É—î –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
- –ì–µ–Ω–µ—Ä—É—î –ø–æ–≤–Ω–∏–π –∑–≤—ñ—Ç

### 2. –î–µ—Ç–µ–∫—Ü—ñ—è –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ


python main.py --mode detect --image path/to/image.jpg --threshold 0.5


–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:
- `--image`: —à–ª—è—Ö –¥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- `--threshold`: –ø–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º 0.5)
- `--checkpoint`: —à–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)

### 3. –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ


python main.py --mode train --data-dir ./data --epochs 10 --batch-size 4 --lr 0.005


–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:
- `--data-dir`: –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑ –¥–∞–Ω–∏–º–∏
- `--epochs`: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö
- `--batch-size`: —Ä–æ–∑–º—ñ—Ä –±–∞—Ç—á—É
- `--lr`: —à–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è
- `--num-classes`: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤

### 4. –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ


python main.py --mode evaluate --checkpoint ./checkpoints/best_model.pth


## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–∏—Ö

### –§–æ—Ä–º–∞—Ç –∞–Ω–æ—Ç–∞—Ü—ñ–π (JSON)

json
[
  {
    "image_path": "image_001.jpg",
    "boxes": [
      [x1, y1, x2, y2],
      [x1, y1, x2, y2]
    ],
    "labels": [1, 3]
  }
]


–î–µ:
- `boxes`: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ bounding boxes —É —Ñ–æ—Ä–º–∞—Ç—ñ [x1, y1, x2, y2]
- `labels`: ID –∫–ª–∞—Å—ñ–≤ –æ–±'—î–∫—Ç—ñ–≤

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç—É


data/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ images/             
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_001.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_002.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ annotations.json     
‚îî‚îÄ‚îÄ val/
    ‚îú‚îÄ‚îÄ images/
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ annotations.json


##  –û—Å–Ω–æ–≤–Ω—ñ –º–æ–¥—É–ª—ñ

### 1. config.py
–ú—ñ—Å—Ç–∏—Ç—å –≤—Å—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏:
- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª—ñ
- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
- –®–ª—è—Ö–∏ –¥–æ –¥–∞–Ω–∏—Ö
- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó

### 2. model.py
–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è Faster R-CNN:
- –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
- –î–µ—Ç–µ–∫—Ü—ñ—è –æ–±'—î–∫—Ç—ñ–≤
- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è/–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —á–µ–∫–ø–æ—ñ–Ω—Ç—ñ–≤

### 3. visualizer.py
–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:
- –ú–∞–ª—é–≤–∞–Ω–Ω—è bounding boxes
- –ü–æ–±—É–¥–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–µ—Ç–µ–∫—Ü—ñ–π
- –ì—Ä–∞—Ñ—ñ–∫–∏ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –∫–ª–∞—Å—ñ–≤

### 4. metrics.py
–û–±—á–∏—Å–ª–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫:
- **IoU (Intersection over Union)**
- **mAP (Mean Average Precision)**
- **Precision & Recall**
- **F1-score**

### 5. trainer.py
–ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ:
- –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π —Ü–∏–∫–ª
- –í–∞–ª—ñ–¥–∞—Ü—ñ—è
- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —á–µ–∫–ø–æ—ñ–Ω—Ç—ñ–≤
- –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —ñ—Å—Ç–æ—Ä—ñ—ó –Ω–∞–≤—á–∞–Ω–Ω—è

### 6. report_generator.py
–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤:
- –¢–µ–∫—Å—Ç–æ–≤—ñ –∑–≤—ñ—Ç–∏
- JSON –∑–≤—ñ—Ç–∏
- –í—ñ–∑—É–∞–ª—å–Ω—ñ –∑–≤—ñ—Ç–∏ –∑ –≥—Ä–∞—Ñ—ñ–∫–∞–º–∏

## –ú–µ—Ç—Ä–∏–∫–∏ —è–∫–æ—Å—Ç—ñ

### IoU (Intersection over Union)
–ú—ñ—Ä–∞ –ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è –º—ñ–∂ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏–º —Ç–∞ —Å–ø—Ä–∞–≤–∂–Ω—ñ–º bounding box:


IoU = Area of Overlap / Area of Union


### mAP (Mean Average Precision)
–°–µ—Ä–µ–¥–Ω—è —Ç–æ—á–Ω—ñ—Å—Ç—å –ø–æ –≤—Å—ñ—Ö –∫–ª–∞—Å–∞—Ö –ø—Ä–∏ —Ä—ñ–∑–Ω–∏—Ö –ø–æ—Ä–æ–≥–∞—Ö IoU.

### Precision & Recall
- **Precision**: —á–∞—Å—Ç–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö –¥–µ—Ç–µ–∫—Ü—ñ–π —Å–µ—Ä–µ–¥ —É—Å—ñ—Ö –¥–µ—Ç–µ–∫—Ü—ñ–π
- **Recall**: —á–∞—Å—Ç–∫–∞ –≤–∏—è–≤–ª–µ–Ω–∏—Ö –æ–±'—î–∫—Ç—ñ–≤ —Å–µ—Ä–µ–¥ —É—Å—ñ—Ö –æ–±'—î–∫—Ç—ñ–≤

##  –ü—Ä–∏–∫–ª–∞–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

### –ü—Ä–∏–∫–ª–∞–¥ 1: –î–µ—Ç–µ–∫—Ü—ñ—è –Ω–∞ –≤–ª–∞—Å–Ω–æ–º—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ

python
from model import FasterRCNNDetector
from visualizer import DetectionVisualizer
from utils import load_image

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
model = FasterRCNNDetector(pretrained=True)
visualizer = DetectionVisualizer()

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
image, image_tensor = load_image('my_image.jpg')

# –î–µ—Ç–µ–∫—Ü—ñ—è
predictions = model.predict([image_tensor], threshold=0.5)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
image_with_boxes = visualizer.draw_boxes(image, predictions[0])
visualizer.visualize_predictions(image, predictions[0], 
                                save_path='result.png')


### –ü—Ä–∏–∫–ª–∞–¥ 2: –ù–∞–≤—á–∞–Ω–Ω—è –Ω–∞ –≤–ª–∞—Å–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ

python
from model import FasterRCNNDetector
from dataset import ObjectDetectionDataset, DatasetBuilder
from trainer import ModelTrainer

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É
train_dataset = ObjectDetectionDataset(
    root_dir='./data/train',
    annotation_file='./data/train/annotations.json',
    mode='train'
)

train_loader = DatasetBuilder.build_dataloader(train_dataset)

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ
model = FasterRCNNDetector(num_classes=10, pretrained=True)

# –ù–∞–≤—á–∞–Ω–Ω—è
trainer = ModelTrainer(model, train_loader)
history = trainer.train(num_epochs=10)

# –ì—Ä–∞—Ñ—ñ–∫–∏
trainer.plot_training_history(save_path='training.png')


### –ü—Ä–∏–∫–ª–∞–¥ 3: –û–±—á–∏—Å–ª–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫

python
from metrics import DetectionMetrics

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
metrics = DetectionMetrics(num_classes=10, iou_threshold=0.5)

# –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ
results = metrics.evaluate_model(predictions, ground_truths)

# –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
print(f"mAP: {results['overall']['mAP']:.4f}")
print(f"Precision: {results['overall']['mean_precision']:.4f}")
print(f"Recall: {results['overall']['mean_recall']:.4f}")


### –ü—Ä–∏–∫–ª–∞–¥ 4: –î–æ–Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ

python
from trainer import ModelTrainer

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
model.load_checkpoint('checkpoints/base_model.pth')

# –î–æ–Ω–∞–≤—á–∞–Ω–Ω—è –∑ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–∏–º backbone
history = trainer.fine_tune(num_epochs=5, freeze_backbone=True)


## –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—ñ–≤

–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≥–µ–Ω–µ—Ä—É—î —Ç—Ä–∏ —Ç–∏–ø–∏ –∑–≤—ñ—Ç—ñ–≤:

1. **–¢–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç** (`report.txt`):
   - –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å
   - –Ü—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è
   - –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü—ñ–Ω–∫–∏
   - –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–µ—Ç–µ–∫—Ü—ñ—ó

2. **JSON –∑–≤—ñ—Ç** (`report.json`):
   - –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ—ó –æ–±—Ä–æ–±–∫–∏

3. **–í—ñ–∑—É–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç** (`visual_report.png`):
   - –ì—Ä–∞—Ñ—ñ–∫–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
   - –†–æ–∑–ø–æ–¥—ñ–ª –º–µ—Ç—Ä–∏–∫ –ø–æ –∫–ª–∞—Å–∞—Ö
   - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–µ—Ç–µ–∫—Ü—ñ–π

## –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

–û—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤ `config.py`:

python
# –ú–æ–¥–µ–ª—å
NUM_CLASSES = 3
DETECTION_THRESHOLD = 0.5

# –ù–∞–≤—á–∞–Ω–Ω—è
LEARNING_RATE = 0.005
BATCH_SIZE = 4
NUM_EPOCHS = 10

# –ü—Ä–∏—Å—Ç—Ä—ñ–π
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


## üîç –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏

- **–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è**: JPG, PNG, BMP
- **–ê–Ω–æ—Ç–∞—Ü—ñ—ó**: JSON (–≤–ª–∞—Å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç), COCO format
- **–ú–æ–¥–µ–ª—ñ**: PyTorch checkpoint (.pth)

## –í–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ

–°–∏—Å—Ç–µ–º–∞ –∑–±–µ—Ä—ñ–≥–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ –Ω–∞—Å—Ç—É–ø–Ω–∏—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è—Ö:


output/
‚îú‚îÄ‚îÄ visualizations/     # –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –¥–µ—Ç–µ–∫—Ü—ñ—è–º–∏
‚îú‚îÄ‚îÄ predictions/        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
checkpoints/           # –ó–±–µ—Ä–µ–∂–µ–Ω—ñ –º–æ–¥–µ–ª—ñ
reports/              # –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—ñ –∑–≤—ñ—Ç–∏


##  –ü–æ–º–∏–ª–∫–∏ —Ç–∞ —ó—Ö –≤–∏—Ä—ñ—à–µ–Ω–Ω—è

### –ü—Ä–æ–±–ª–µ–º–∞: CUDA out of memory
**–†—ñ—à–µ–Ω–Ω—è**: –ó–º–µ–Ω—à—ñ—Ç—å `BATCH_SIZE` –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç
**–†—ñ—à–µ–Ω–Ω—è**: –ü—Ä–æ–≥—Ä–∞–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä–∏—Ç—å —Ç–µ—Å—Ç–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–∏–∑—å–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü—ñ—ó
**–†—ñ—à–µ–Ω–Ω—è**: 
- –ó–º–µ–Ω—à—ñ—Ç—å `DETECTION_THRESHOLD`




